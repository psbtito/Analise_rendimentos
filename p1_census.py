# -*- coding: utf-8 -*-
"""P1_Census.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HBepyOvU7I5BP51uSB2BlHJX4gOOQwIQ

# **Estudo do rendimento anual**

Neste arquivo iremos fazer um breve estudo dos fatores que podem interferir no rendimento anual das pessoas. Iremos análisar fatores como gênero, idade e localização e como cada um deles interferem no ganho anual. Utilizaremos modelos de classificação para filtrar o modelo de melhor desempenho no estudo. Algumas etapas de tratamento e pré-processamento dos dados serão ocultadas a fim de termos um ganho efetivo no tempo de leitura do arquivo.
"""

!pip install pyod

!pip install -U pandas-profiling

# Commented out IPython magic to ensure Python compatibility.
#Bibliotecas
import pandas as pd 

#-------------------------------
import matplotlib.pyplot as plt
import seaborn as sns

# %matplotlib inline
# %pylab inline
#-------------------------------
import numpy as np

#Carregamento e ajustes na base de dados
data = pd.read_csv('/content/census.csv')

data.columns = ['idade', 'classe_trabalho', 'altura_final', 'escolaridade', \
                'escolaridade_num', 'estado_civil', 'ocupacao', 'parentes', \
                'raca', 'sexo', 'ganho_capital', 'perda_capital',\
                'horas_semana', 'pais_origem', 'rendimento']

data.drop(columns = ['altura_final','ganho_capital', 'perda_capital', 'horas_semana'],  inplace=True)

data.iloc[:1, :]

#Informações básicas do conjunto de dados
#from pandas_profiling import ProfileReport
#profile = ProfileReport(data, title='Rendimento Anual', html={'style':{'full_width':True}})
#profile.to_notebook_iframe()

#Informações estatísticas da base de dados
data.describe()

#Agrupamento dos Dados com base no estado civil
(data.groupby('escolaridade').size()/32561)*100

"""# **Visualização dos Dados**
Agora, vamos analisar os dados principalmente os dados estatísticos e representação gráfica dos mesmos. Iremos avaliar como nossos dados estão distribuídos com base em alguns aspectos mensionados anteriormente como: sexo, escolaridade e raça. 

A seguir vemos que a maior parte dos dados disponíveis representam ganhos anuais abaixo de 50K. Nossa missão agora é entender quais são os aspectos responsáveis por este resultado e como cada um deles interfere no resultado.
"""

#Distribuição geral dos ganhos acima de 50k
data['rendimento'].value_counts().plot(kind='pie', autopct='%.2f%%')
plt.axis('equal')

"""O primeiro atributo que vamos analisar é o gênero. No gráfico abaixo vemos que a maior parte dos dados representa o ganho de pessoas do sexo masculino, seguido do gráfico que representa a distribuição dos ganhos com base neste quesito. Neste gráfico fica evidente a discrepância dos ganhos efetivos anuais existente no que diz respeito ao gênero, revelando que os homens ganham bem mais que as mulheres em ambos cenários (<=50K e >50K)."""

#Distribuição dos dados por Sexo
data['sexo'].value_counts().plot(kind='pie', autopct='%.2f%%')
plt.axis('equal')

# Distribuição dos rendimentos por sexo.
sns.factorplot('rendimento', data=data, hue='sexo', kind='count')

"""Agora vamos avaliar o ganho anual com respeito à idade. O gráfico seguinte nos mostra que a maior parte das pessoas que compõe o nosso conjunto de dados está na faixa etária de 20 a 50 anos. Logo abaixo, temos que essa faixa etária também compreende às pessoas com maior ganho efetivo anual."""

#Distribuição dos dados por idade
data['idade'].hist(bins=int(data.idade.max()), figsize=(15, 5))

def plot_line_graph(x, hue):
    fig = sns.FacetGrid(data, hue=hue, aspect=4)
    fig.map(sns.kdeplot, x, shade=True)
    fig.set(xlim=(0, data[x].max()))
    fig.add_legend()
    return fig

plot_line_graph('idade', 'rendimento')

# Distribuição dos rendimentos por Raça.
sns.factorplot('rendimento', data=data, hue='raca', kind='count')

#Distribuição dos rendimentos pela escolaridade
sns.factorplot('rendimento', data=data, hue='escolaridade', kind='count')

#Relação dos Atributos com a Classe
#sns.pairplot(data, diag_kind='kde', hue='rendimento')

sns.pairplot(data,hue="rendimento")

"""# **Pré-Processamento dos Dados**

Neste momento, daremos início à etapa de pré-processamento dos dados. Iremos por exemplo, tratar a escala dos dados, codificar dados categóricos, redimensionar os dados, etc. Para um maior detalhamento dessas etapas e outras recomenda-se consultar a documentação Python no link https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing

Grande parte das etapas de pré-processamento não serão detalhadas neste arquivo.

**Divisão dos dados em atributos e variável alvo**
"""

atributos = data.iloc[:, :10].values
alvo =data.iloc[:,10:11].values

"""**Codificação dos dados categóricos**"""

from sklearn.preprocessing import LabelEncoder

labelencoder_atributos = LabelEncoder()

for i in range(0, 10):
  if type(data.iloc[1,i])==str:
    atributos[:, i] = labelencoder_atributos.fit_transform(atributos[:, i])

"""**Escalonamento dos dados**"""

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
atributos = scaler.fit_transform(atributos)

"""**Divisão dos dados para treino e teste**"""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(atributos, alvo, test_size=0.15, random_state=0)

"""**Redimensionando conjunto de dados**

Esta é uma etapa que deve ser utilizada com a finalidade de testar o desempenho dos algoritmos. É um processo importante, que na maior parte das vezes atribui uma eficiência significativa no que tange ao custo da máquina e a rapidez dos testes.
"""

from sklearn.decomposition import PCA

pca = PCA(n_components = 6)
X_train = pca.fit_transform(X_train)
X_test = pca.transform(X_test)
componentes = pca.explained_variance_ratio_

"""# **Avaliando Modelos de Classificação**
Agora daremos que temos um panorama mais claro de como cada um dos atributos estão relacionados com o rendimento, vamos agora avaliar métodos de classificação com base nesses atributos.
"""

from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

def nivel_precis(y_test,previsoes):
    print('Nível de Precisão é: ',accuracy_score(y_test,previsoes)*100)
    #print(confusion_matrix(y_test, previsoes))
    #print(classification_report(y_test,previsoes))

"""**Aplicando modelos de classificação**"""

from sklearn.ensemble import RandomForestClassifier

model_1 = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)
model_1.fit(X_train, y_train)
previsoes = model_1.predict(X_test)

nivel_precis(y_test,previsoes)

from sklearn.linear_model import LogisticRegression

model_2 = LogisticRegression()
model_2.fit(X_train,y_train)
previsoes = model_2.predict(X_test)

nivel_precis(y_test,previsoes)

from sklearn.tree import DecisionTreeClassifier

model_3 = DecisionTreeClassifier()
model_3.fit(X_train,y_train)
previsoe = model_3.predict(X_test)

nivel_precis(y_test,previsoes)

from sklearn.naive_bayes import GaussianNB

model_4 = GaussianNB()
model_4.fit(X_train,y_train)
previsoe = model_4.predict(X_test)

nivel_precis(y_test, previsoe)

"""# **Conclusão**
No que tange ao desempenho dos modelos apresentados anteriormente, temos que de modo geral, apresentaram bons resultados tendo por sua vez, acurácias por volta de 80% este cenário se deu sem o redimensionamento dos dados. Quanto ao redimensionamento dos dados, avaliamos que diante da perda de acurácia não significativa devemos considerar sim o redimensionamento dos dados levando em conta o melhor desempenho da máquina.
"""